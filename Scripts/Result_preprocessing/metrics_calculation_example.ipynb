{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make sure that you got the pulled results from Result_pulling_example.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import statistics\n",
    "suffix = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_accu(list_A, list_B):\n",
    "    count = 0\n",
    "    for i in range(len(list_A)):\n",
    "        if list_A[i] == list_B[i]:\n",
    "            count += 1\n",
    "    over_accu = float(count)/len(list_A)\n",
    "    return over_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list = ['pbmc', 'pancreas', 'tabula_lung', 'tabula_full', 'simulation']\n",
    "for item in item_list:\n",
    "    prediction_result = pd.read_csv(os.path.join(item + '_result' + suffix))\n",
    "    if item == 'pbmc':\n",
    "        labels_true = list(prediction_result['orig_id'])\n",
    "    elif item == 'pancreas':\n",
    "        labels_true = list(prediction_result['celltype'])\n",
    "    elif item == 'tabula_lung' or item == 'tabula_full':\n",
    "        labels_true = list(prediction_result['cell_ontology_class'])\n",
    "    else:\n",
    "        labels_true = list(prediction_result['Group'])\n",
    "    if item != 'tabula_full':\n",
    "        seurat_pred = list(prediction_result['seurat_pred'])\n",
    "        garnett_pred = list(prediction_result['garnett_pred'])\n",
    "        singler_pred = list(prediction_result['singler_pred'])\n",
    "        scmap_pred = list(prediction_result['scmap_pred'])\n",
    "        CP_pred = list(prediction_result['CP_pred'])\n",
    "        RPC_pred = list(prediction_result['RPC_pred'])\n",
    "        SCINA_pred = list(prediction_result['SCINA_pred'])\n",
    "        CHETAH_pred = list(prediction_result['CHETAH_pred'])\n",
    "        scID_pred = list(prediction_result['scID_pred'])\n",
    "        singleCellNet_pred = list(prediction_result['singleCellNet_pred'])\n",
    "        prediciton_list = [garnett_pred, scmap_pred, seurat_pred, singler_pred, CP_pred, RPC_pred, SCINA_pred, CHETAH_pred, scID_pred, singleCellNet_pred]\n",
    "        ###overall acc####\n",
    "        overall_acc = list()\n",
    "        for method in prediciton_list:\n",
    "            overall_acc.append(over_accu(labels_true, method))\n",
    "        ###adjusted_rand_index###\n",
    "        adjusted_rand_index = list()\n",
    "        for method in prediciton_list:\n",
    "            adjusted_rand_index.append(metrics.adjusted_rand_score(labels_true, method))\n",
    "        ###hcv_score#####\n",
    "        hcv_score = list()\n",
    "        for method in prediciton_list:\n",
    "            hcv_score.append(metrics.homogeneity_completeness_v_measure(labels_true, method))\n",
    "        homo = list()\n",
    "        comp = list()\n",
    "        v_score = list()\n",
    "        for hcv in hcv_score:\n",
    "            homo.append(hcv[0])\n",
    "            comp.append(hcv[1])\n",
    "            v_score.append(hcv[2])\n",
    "        d_1 = pd.DataFrame({'score': pd.Series(overall_acc), 'test':pd.Series(['Overall Accuracy']*10), 'method':pd.Series(['Garnett', 'scmap', 'Seurat', 'SingleR', 'CP', 'RPC', 'SCINA', 'CHETAH', 'scID', 'singleCellNet']),'dataset':pd.Series([item]*10)})\n",
    "        d_2 = pd.DataFrame({'score': pd.Series(adjusted_rand_index), 'test':pd.Series(['Adj_rand_index']*10), 'method':pd.Series(['Garnett', 'scmap', 'Seurat', 'SingleR', 'CP', 'RPC', 'SCINA', 'CHETAH', 'scID', 'singleCellNet']),'dataset':pd.Series([item]*10)})\n",
    "        d_3 = pd.DataFrame({'score': pd.Series(homo), 'test':pd.Series(['Homogeneity']*10), 'method':pd.Series(['Garnett', 'scmap', 'Seurat', 'SingleR', 'CP', 'RPC', 'SCINA', 'CHETAH', 'scID', 'singleCellNet']),'dataset':pd.Series([item]*10)})\n",
    "        d_4 = pd.DataFrame({'score': pd.Series(comp), 'test':pd.Series(['Completeness']*10), 'method':pd.Series(['Garnett', 'scmap', 'Seurat', 'SingleR', 'CP', 'RPC', 'SCINA', 'CHETAH', 'scID', 'singleCellNet']),'dataset':pd.Series([item]*10)})\n",
    "        d_5 = pd.DataFrame({'score': pd.Series(v_score), 'test':pd.Series(['V-measure']*10), 'method':pd.Series(['Garnett', 'scmap', 'Seurat', 'SingleR', 'CP', 'RPC', 'SCINA', 'CHETAH', 'scID', 'singleCellNet']),'dataset':pd.Series([item]*10)})\n",
    "        result = pd.concat([d_1,d_2, d_3, d_4, d_5])\n",
    "        path = os.path.join(item + '_metrics_result' + suffix)\n",
    "        result.to_csv(path, encoding='utf-8', index=False)\n",
    "    else:\n",
    "        seurat_pred = list(prediction_result['seurat_pred'])\n",
    "        singler_pred = list(prediction_result['singler_pred'])\n",
    "        scmap_pred = list(prediction_result['scmap_pred'])\n",
    "        CP_pred = list(prediction_result['CP_pred'])\n",
    "        RPC_pred = list(prediction_result['RPC_pred'])\n",
    "        SCINA_pred = list(prediction_result['SCINA_pred'])\n",
    "        CHETAH_pred = list(prediction_result['CHETAH_pred'])\n",
    "        scID_pred = list(prediction_result['scID_pred'])\n",
    "        singleCellNet_pred = list(prediction_result['singleCellNet_pred'])\n",
    "        prediciton_list = [scmap_pred, seurat_pred, singler_pred, CP_pred, RPC_pred, SCINA_pred, CHETAH_pred, scID_pred, singleCellNet_pred]\n",
    "        ###overall acc####\n",
    "        overall_acc = list()\n",
    "        for method in prediciton_list:\n",
    "            overall_acc.append(over_accu(labels_true, method))\n",
    "        ###adjusted_rand_index###\n",
    "        adjusted_rand_index = list()\n",
    "        for method in prediciton_list:\n",
    "            adjusted_rand_index.append(metrics.adjusted_rand_score(labels_true, method))\n",
    "        ###hcv_score#####\n",
    "        hcv_score = list()\n",
    "        for method in prediciton_list:\n",
    "            hcv_score.append(metrics.homogeneity_completeness_v_measure(labels_true, method))\n",
    "        homo = list()\n",
    "        comp = list()\n",
    "        v_score = list()\n",
    "        for hcv in hcv_score:\n",
    "            homo.append(hcv[0])\n",
    "            comp.append(hcv[1])\n",
    "            v_score.append(hcv[2])\n",
    "        d_1 = pd.DataFrame({'score': pd.Series(overall_acc), 'test':pd.Series(['Overall Accuracy']*9), 'method':pd.Series(['scmap', 'Seurat', 'SingleR', 'CP', 'RPC', 'SCINA', 'CHETAH', 'scID', 'singleCellNet']),'dataset':pd.Series([item]*9)})\n",
    "        d_2 = pd.DataFrame({'score': pd.Series(adjusted_rand_index), 'test':pd.Series(['Adj_rand_index']*9), 'method':pd.Series(['scmap', 'Seurat', 'SingleR', 'CP', 'RPC', 'SCINA', 'CHETAH', 'scID', 'singleCellNet']),'dataset':pd.Series([item]*9)})\n",
    "        d_3 = pd.DataFrame({'score': pd.Series(homo), 'test':pd.Series(['Homogeneity']*9), 'method':pd.Series(['scmap', 'Seurat', 'SingleR', 'CP', 'RPC', 'SCINA', 'CHETAH', 'scID', 'singleCellNet']),'dataset':pd.Series([item]*9)})\n",
    "        d_4 = pd.DataFrame({'score': pd.Series(comp), 'test':pd.Series(['Completeness']*9), 'method':pd.Series(['scmap', 'Seurat', 'SingleR', 'CP', 'RPC', 'SCINA', 'CHETAH', 'scID', 'singleCellNet']),'dataset':pd.Series([item]*9)})\n",
    "        d_5 = pd.DataFrame({'score': pd.Series(v_score), 'test':pd.Series(['V-measure']*9), 'method':pd.Series(['scmap', 'Seurat', 'SingleR', 'CP', 'RPC', 'SCINA', 'CHETAH', 'scID', 'singleCellNet']),'dataset':pd.Series([item]*9)})\n",
    "        result = pd.concat([d_1,d_2, d_3, d_4, d_5])\n",
    "        path = os.path.join(item + '_metrics_result' + suffix)\n",
    "        result.to_csv(path, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Then use the resulting metrics to plot corresponding graphs in downstream analysis#####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
